# Testing Phase 1: Foundation - Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Set up comprehensive testing infrastructure with tools, fixtures, and reorganized test structure.

**Architecture:** Bottom-up testing approach with layered test organization (unit/integration/e2e/performance/security). Install Standard QA toolkit, create DICOM fixture library, audit and migrate existing tests to new structure.

**Tech Stack:** pytest, pytest-cov, pytest-asyncio, pytest-xdist, pytest-benchmark, pytest-html, bandit, safety, locust, faker, factory-boy

**Duration:** Week 1-2

**Deliverables:**
- ‚úÖ All testing tools installed and configured
- ‚úÖ Layered test directory structure created
- ‚úÖ DICOM fixture library with 20+ samples
- ‚úÖ Test factories and shared fixtures
- ‚úÖ Existing tests audited and migrated
- ‚úÖ Coverage, CI/CD, and pre-commit configurations

---

## Task 1: Install Testing Dependencies

**Files:**
- Modify: `pyproject.toml`

**Step 1: Add testing dependencies to pyproject.toml**

Edit the `[project.optional-dependencies]` section:

```toml
[project.optional-dependencies]
dev = [
    # Existing
    "ruff>=0.8.0",
    "mypy>=1.13.0",
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",

    # Coverage & Reporting
    "pytest-cov>=4.1.0",
    "coverage[toml]>=7.4.0",

    # Performance Testing
    "pytest-benchmark>=4.0.0",
    "locust>=2.20.0",

    # Security
    "bandit>=1.7.6",
    "safety>=3.0.0",

    # Test Execution
    "pytest-xdist>=3.5.0",
    "pytest-html>=4.1.0",

    # Test Data
    "faker>=22.0.0",
    "factory-boy>=3.3.0",
]
```

**Step 2: Install dependencies**

Run: `pip install -e ".[dev]"`

Expected: All packages install successfully

**Step 3: Verify installations**

Run:
```bash
pytest --version
pytest --co --markers | grep -E "unit|integration|e2e"
bandit --version
locust --version
```

Expected: All tools report versions correctly

**Step 4: Commit**

```bash
git add pyproject.toml
git commit -m "build: add comprehensive testing dependencies

- Add pytest-cov, coverage for code coverage
- Add pytest-benchmark, locust for performance testing
- Add bandit, safety for security scanning
- Add pytest-xdist, pytest-html for test execution
- Add faker, factory-boy for test data generation

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 2: Configure Pytest and Test Markers

**Files:**
- Modify: `pyproject.toml`

**Step 1: Update pytest configuration**

Add to `pyproject.toml`:

```toml
[tool.pytest.ini_options]
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "-v",
    "--strict-markers",
    "--tb=short",
    "--cov-report=term-missing",
]
markers = [
    "unit: Unit tests for services, models, utilities",
    "integration: Integration tests for API endpoints",
    "e2e: End-to-end workflow tests",
    "slow: Tests that take longer than 1 second",
    "security: Security and penetration tests",
]
```

**Step 2: Verify pytest configuration**

Run: `pytest --markers`

Expected: Should list all custom markers (unit, integration, e2e, slow, security)

**Step 3: Commit**

```bash
git add pyproject.toml
git commit -m "test: configure pytest with custom markers

- Add test markers for unit/integration/e2e/slow/security
- Configure pytest paths and discovery patterns
- Set default addopts for verbose output

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 3: Configure Code Coverage

**Files:**
- Create: `.coveragerc`

**Step 1: Create coverage configuration**

```ini
[run]
source = app
omit =
    */tests/*
    */venv/*
    */.venv/*
    */migrations/*
    */__pycache__/*

[report]
precision = 2
show_missing = true
skip_covered = false
fail_under = 90.0

exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @abstractmethod

[html]
directory = htmlcov

[xml]
output = coverage.xml
```

**Step 2: Test coverage configuration**

Run: `pytest tests/ --cov=app --cov-report=term-missing`

Expected: Coverage report generated (may be low initially, that's expected)

**Step 3: Commit**

```bash
git add .coveragerc
git commit -m "test: add coverage configuration

- Set 90% coverage threshold
- Configure source paths and exclusions
- Add HTML and XML report generation
- Define exclude patterns for coverage

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 4: Create Layered Test Directory Structure

**Files:**
- Create: Multiple directories

**Step 1: Create new test directory structure**

Run:
```bash
mkdir -p tests/unit/models
mkdir -p tests/unit/services
mkdir -p tests/unit/utils
mkdir -p tests/integration
mkdir -p tests/e2e
mkdir -p tests/performance/load_tests
mkdir -p tests/security
mkdir -p tests/fixtures/dicom/valid
mkdir -p tests/fixtures/dicom/edge_cases
mkdir -p tests/fixtures/dicom/invalid
```

**Step 2: Verify directory structure**

Run: `tree tests -L 3 -d`

Expected: Should show the layered structure

**Step 3: Create __init__.py files**

Run:
```bash
touch tests/unit/__init__.py
touch tests/unit/models/__init__.py
touch tests/unit/services/__init__.py
touch tests/unit/utils/__init__.py
touch tests/integration/__init__.py
touch tests/e2e/__init__.py
touch tests/performance/__init__.py
touch tests/security/__init__.py
touch tests/fixtures/__init__.py
```

**Step 4: Commit**

```bash
git add tests/
git commit -m "test: create layered test directory structure

- Add unit/ for services, models, utils tests
- Add integration/ for API endpoint tests
- Add e2e/ for end-to-end workflow tests
- Add performance/ for benchmarks and load tests
- Add security/ for security scans
- Add fixtures/dicom/ for test DICOM files

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 5: Create DICOM Test Fixture Factory

**Files:**
- Create: `tests/fixtures/factories.py`

**Step 1: Write the DICOM factory class**

```python
"""Test data factories for creating DICOM instances."""

import uuid
from io import BytesIO
from datetime import datetime

import pydicom
from pydicom.dataset import Dataset, FileDataset
from pydicom.uid import ExplicitVRLittleEndian, ImplicitVRLittleEndian, generate_uid


class DicomFactory:
    """Factory for creating test DICOM files."""

    @staticmethod
    def create_ct_image(
        patient_id: str = "TEST-001",
        patient_name: str = "Test^Patient",
        study_uid: str | None = None,
        series_uid: str | None = None,
        sop_uid: str | None = None,
        accession_number: str | None = None,
        study_date: str | None = None,
        modality: str = "CT",
        with_pixel_data: bool = False,
        transfer_syntax: str = ExplicitVRLittleEndian,
    ) -> bytes:
        """
        Create a minimal CT DICOM instance.

        Args:
            patient_id: Patient identifier
            patient_name: Patient name in DICOM format (Last^First)
            study_uid: Study Instance UID (generated if None)
            series_uid: Series Instance UID (generated if None)
            sop_uid: SOP Instance UID (generated if None)
            accession_number: Accession number (generated if None)
            study_date: Study date YYYYMMDD (today if None)
            modality: DICOM modality
            with_pixel_data: Include dummy pixel data
            transfer_syntax: Transfer syntax UID

        Returns:
            DICOM file as bytes
        """
        study_uid = study_uid or generate_uid()
        series_uid = series_uid or generate_uid()
        sop_uid = sop_uid or generate_uid()
        accession_number = accession_number or f"ACC-{uuid.uuid4().hex[:8]}"
        study_date = study_date or datetime.now().strftime("%Y%m%d")

        # File meta information
        file_meta = Dataset()
        file_meta.MediaStorageSOPClassUID = "1.2.840.10008.5.1.4.1.1.2"  # CT Image
        file_meta.MediaStorageSOPInstanceUID = sop_uid
        file_meta.TransferSyntaxUID = transfer_syntax
        file_meta.ImplementationClassUID = "1.2.826.0.1.3680043.8.498.1"

        # Create dataset
        ds = FileDataset(
            filename_or_obj=BytesIO(),
            dataset=Dataset(),
            file_meta=file_meta,
            preamble=b"\x00" * 128,
        )

        # Required DICOM attributes
        ds.SOPClassUID = "1.2.840.10008.5.1.4.1.1.2"
        ds.SOPInstanceUID = sop_uid
        ds.StudyInstanceUID = study_uid
        ds.SeriesInstanceUID = series_uid
        ds.PatientID = patient_id
        ds.PatientName = patient_name
        ds.StudyDate = study_date
        ds.StudyTime = "120000"
        ds.Modality = modality
        ds.AccessionNumber = accession_number
        ds.StudyDescription = "Test Study"
        ds.SeriesDescription = "Test Series"
        ds.SeriesNumber = 1
        ds.InstanceNumber = 1

        # Add pixel data if requested
        if with_pixel_data:
            import numpy as np
            ds.Rows = 512
            ds.Columns = 512
            ds.BitsAllocated = 16
            ds.BitsStored = 16
            ds.HighBit = 15
            ds.SamplesPerPixel = 1
            ds.PhotometricInterpretation = "MONOCHROME2"
            ds.PixelRepresentation = 0
            ds.PixelData = np.zeros((512, 512), dtype=np.uint16).tobytes()

        # Save to bytes
        buffer = BytesIO()
        ds.save_as(buffer, write_like_original=False)
        return buffer.getvalue()

    @staticmethod
    def create_mri_image(
        patient_id: str = "TEST-002",
        patient_name: str = "MRI^Patient",
        study_uid: str | None = None,
        series_uid: str | None = None,
        sop_uid: str | None = None,
        modality: str = "MR",
        with_pixel_data: bool = False,
    ) -> bytes:
        """Create a minimal MRI DICOM instance."""
        study_uid = study_uid or generate_uid()
        series_uid = series_uid or generate_uid()
        sop_uid = sop_uid or generate_uid()

        file_meta = Dataset()
        file_meta.MediaStorageSOPClassUID = "1.2.840.10008.5.1.4.1.1.4"  # MR Image
        file_meta.MediaStorageSOPInstanceUID = sop_uid
        file_meta.TransferSyntaxUID = ExplicitVRLittleEndian
        file_meta.ImplementationClassUID = "1.2.826.0.1.3680043.8.498.1"

        ds = FileDataset(
            filename_or_obj=BytesIO(),
            dataset=Dataset(),
            file_meta=file_meta,
            preamble=b"\x00" * 128,
        )

        ds.SOPClassUID = "1.2.840.10008.5.1.4.1.1.4"
        ds.SOPInstanceUID = sop_uid
        ds.StudyInstanceUID = study_uid
        ds.SeriesInstanceUID = series_uid
        ds.PatientID = patient_id
        ds.PatientName = patient_name
        ds.StudyDate = datetime.now().strftime("%Y%m%d")
        ds.StudyTime = "140000"
        ds.Modality = modality
        ds.AccessionNumber = f"ACC-{uuid.uuid4().hex[:8]}"
        ds.StudyDescription = "MRI Test Study"
        ds.SeriesDescription = "T1 Weighted"
        ds.SeriesNumber = 1
        ds.InstanceNumber = 1

        if with_pixel_data:
            import numpy as np
            ds.Rows = 256
            ds.Columns = 256
            ds.BitsAllocated = 16
            ds.BitsStored = 16
            ds.HighBit = 15
            ds.SamplesPerPixel = 1
            ds.PhotometricInterpretation = "MONOCHROME2"
            ds.PixelRepresentation = 0
            ds.PixelData = np.zeros((256, 256), dtype=np.uint16).tobytes()

        buffer = BytesIO()
        ds.save_as(buffer, write_like_original=False)
        return buffer.getvalue()

    @staticmethod
    def create_multiframe_ct(
        patient_id: str = "TEST-003",
        num_frames: int = 10,
        with_pixel_data: bool = True,
    ) -> bytes:
        """Create a multiframe CT DICOM instance."""
        study_uid = generate_uid()
        series_uid = generate_uid()
        sop_uid = generate_uid()

        file_meta = Dataset()
        file_meta.MediaStorageSOPClassUID = "1.2.840.10008.5.1.4.1.1.2"
        file_meta.MediaStorageSOPInstanceUID = sop_uid
        file_meta.TransferSyntaxUID = ExplicitVRLittleEndian
        file_meta.ImplementationClassUID = "1.2.826.0.1.3680043.8.498.1"

        ds = FileDataset(
            filename_or_obj=BytesIO(),
            dataset=Dataset(),
            file_meta=file_meta,
            preamble=b"\x00" * 128,
        )

        ds.SOPClassUID = "1.2.840.10008.5.1.4.1.1.2"
        ds.SOPInstanceUID = sop_uid
        ds.StudyInstanceUID = study_uid
        ds.SeriesInstanceUID = series_uid
        ds.PatientID = patient_id
        ds.PatientName = "Multiframe^Patient"
        ds.StudyDate = datetime.now().strftime("%Y%m%d")
        ds.StudyTime = "150000"
        ds.Modality = "CT"
        ds.AccessionNumber = f"ACC-{uuid.uuid4().hex[:8]}"
        ds.StudyDescription = "Multiframe CT Study"
        ds.SeriesDescription = "Multiframe Series"
        ds.SeriesNumber = 1
        ds.InstanceNumber = 1
        ds.NumberOfFrames = num_frames

        if with_pixel_data:
            import numpy as np
            ds.Rows = 128
            ds.Columns = 128
            ds.BitsAllocated = 16
            ds.BitsStored = 16
            ds.HighBit = 15
            ds.SamplesPerPixel = 1
            ds.PhotometricInterpretation = "MONOCHROME2"
            ds.PixelRepresentation = 0
            # Create pixel data for all frames
            pixel_array = np.zeros((num_frames, 128, 128), dtype=np.uint16)
            ds.PixelData = pixel_array.tobytes()

        buffer = BytesIO()
        ds.save_as(buffer, write_like_original=False)
        return buffer.getvalue()

    @staticmethod
    def create_invalid_dicom(
        missing_tags: list[str] | None = None,
        invalid_vr: bool = False,
    ) -> bytes:
        """
        Create an invalid DICOM instance for testing error handling.

        Args:
            missing_tags: List of required tag names to omit
            invalid_vr: Include tags with invalid VR

        Returns:
            Invalid DICOM file as bytes
        """
        missing_tags = missing_tags or []

        file_meta = Dataset()
        file_meta.MediaStorageSOPClassUID = "1.2.840.10008.5.1.4.1.1.2"
        file_meta.MediaStorageSOPInstanceUID = generate_uid()
        file_meta.TransferSyntaxUID = ExplicitVRLittleEndian
        file_meta.ImplementationClassUID = "1.2.826.0.1.3680043.8.498.1"

        ds = FileDataset(
            filename_or_obj=BytesIO(),
            dataset=Dataset(),
            file_meta=file_meta,
            preamble=b"\x00" * 128,
        )

        # Add required tags unless explicitly excluded
        if "SOPClassUID" not in missing_tags:
            ds.SOPClassUID = "1.2.840.10008.5.1.4.1.1.2"
        if "SOPInstanceUID" not in missing_tags:
            ds.SOPInstanceUID = generate_uid()
        if "StudyInstanceUID" not in missing_tags:
            ds.StudyInstanceUID = generate_uid()
        if "SeriesInstanceUID" not in missing_tags:
            ds.SeriesInstanceUID = generate_uid()
        if "PatientID" not in missing_tags:
            ds.PatientID = "TEST-999"
        if "Modality" not in missing_tags:
            ds.Modality = "CT"

        buffer = BytesIO()
        ds.save_as(buffer, write_like_original=False)
        return buffer.getvalue()
```

**Step 2: Commit**

```bash
git add tests/fixtures/factories.py
git commit -m "test: add DICOM factory for test data generation

- Create DicomFactory with CT, MRI, multiframe methods
- Support customizable UIDs, patient info, modality
- Optional pixel data generation
- Invalid DICOM factory for error testing

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 6: Create Sample DICOM Fixture Files

**Files:**
- Create: `tests/fixtures/dicom/valid/*.dcm`
- Create: `tests/fixtures/dicom/edge_cases/*.dcm`
- Create: `tests/fixtures/dicom/invalid/*.dcm`
- Create: `tests/fixtures/sample_data.py`

**Step 1: Create script to generate fixture files**

Create `tests/fixtures/sample_data.py`:

```python
"""Generate sample DICOM files for testing."""

from pathlib import Path
from .factories import DicomFactory


def create_fixture_files():
    """Create all DICOM fixture files."""
    fixtures_dir = Path(__file__).parent / "dicom"

    # Valid DICOM files
    valid_dir = fixtures_dir / "valid"
    valid_dir.mkdir(parents=True, exist_ok=True)

    # CT minimal (no pixel data)
    ct_minimal = DicomFactory.create_ct_image(
        patient_id="VALID-001",
        patient_name="Valid^CT^Minimal",
        with_pixel_data=False,
    )
    (valid_dir / "ct_minimal.dcm").write_bytes(ct_minimal)

    # CT with pixels
    ct_with_pixels = DicomFactory.create_ct_image(
        patient_id="VALID-002",
        patient_name="Valid^CT^Pixels",
        with_pixel_data=True,
    )
    (valid_dir / "ct_with_pixels.dcm").write_bytes(ct_with_pixels)

    # MRI T1
    mri_t1 = DicomFactory.create_mri_image(
        patient_id="VALID-003",
        patient_name="Valid^MRI^T1",
        modality="MR",
        with_pixel_data=True,
    )
    (valid_dir / "mri_t1.dcm").write_bytes(mri_t1)

    # MRI T2
    mri_t2 = DicomFactory.create_mri_image(
        patient_id="VALID-004",
        patient_name="Valid^MRI^T2",
        modality="MR",
        with_pixel_data=True,
    )
    (valid_dir / "mri_t2.dcm").write_bytes(mri_t2)

    # Multiframe CT
    multiframe = DicomFactory.create_multiframe_ct(
        patient_id="VALID-005",
        num_frames=10,
        with_pixel_data=True,
    )
    (valid_dir / "multiframe_ct.dcm").write_bytes(multiframe)

    # US (Ultrasound)
    us = DicomFactory.create_ct_image(
        patient_id="VALID-006",
        patient_name="Valid^US",
        modality="US",
        with_pixel_data=True,
    )
    (valid_dir / "us.dcm").write_bytes(us)

    # XA (X-Ray Angiography)
    xa = DicomFactory.create_ct_image(
        patient_id="VALID-007",
        patient_name="Valid^XA",
        modality="XA",
        with_pixel_data=True,
    )
    (valid_dir / "xa.dcm").write_bytes(xa)

    # Edge cases
    edge_dir = fixtures_dir / "edge_cases"
    edge_dir.mkdir(parents=True, exist_ok=True)

    # Empty patient name
    empty_name = DicomFactory.create_ct_image(
        patient_id="EDGE-001",
        patient_name="",
        with_pixel_data=False,
    )
    (edge_dir / "empty_patient_name.dcm").write_bytes(empty_name)

    # Special characters in patient name
    special_chars = DicomFactory.create_ct_image(
        patient_id="EDGE-002",
        patient_name="O'Brien^John=Mary^Dr.^Jr.",
        with_pixel_data=False,
    )
    (edge_dir / "special_chars_name.dcm").write_bytes(special_chars)

    # Very long study description
    long_desc = DicomFactory.create_ct_image(
        patient_id="EDGE-003",
        patient_name="Edge^LongDesc",
        with_pixel_data=False,
    )
    # Would need to modify factory to support this - placeholder for now
    (edge_dir / "long_description.dcm").write_bytes(long_desc)

    # Implicit VR Little Endian
    from pydicom.uid import ImplicitVRLittleEndian
    implicit_vr = DicomFactory.create_ct_image(
        patient_id="EDGE-004",
        patient_name="Edge^ImplicitVR",
        transfer_syntax=ImplicitVRLittleEndian,
        with_pixel_data=False,
    )
    (edge_dir / "implicit_vr.dcm").write_bytes(implicit_vr)

    # Invalid DICOM files
    invalid_dir = fixtures_dir / "invalid"
    invalid_dir.mkdir(parents=True, exist_ok=True)

    # Missing SOPInstanceUID
    missing_sop = DicomFactory.create_invalid_dicom(
        missing_tags=["SOPInstanceUID"]
    )
    (invalid_dir / "missing_sop_uid.dcm").write_bytes(missing_sop)

    # Missing StudyInstanceUID
    missing_study = DicomFactory.create_invalid_dicom(
        missing_tags=["StudyInstanceUID"]
    )
    (invalid_dir / "missing_study_uid.dcm").write_bytes(missing_study)

    # Missing PatientID
    missing_patient = DicomFactory.create_invalid_dicom(
        missing_tags=["PatientID"]
    )
    (invalid_dir / "missing_patient_id.dcm").write_bytes(missing_patient)

    print(f"‚úÖ Created {len(list(valid_dir.glob('*.dcm')))} valid DICOM files")
    print(f"‚úÖ Created {len(list(edge_dir.glob('*.dcm')))} edge case DICOM files")
    print(f"‚úÖ Created {len(list(invalid_dir.glob('*.dcm')))} invalid DICOM files")


if __name__ == "__main__":
    create_fixture_files()
```

**Step 2: Run the script to generate fixtures**

Run: `python -m tests.fixtures.sample_data`

Expected: Should create 15+ DICOM files in tests/fixtures/dicom/

**Step 3: Verify fixture files created**

Run: `find tests/fixtures/dicom -name "*.dcm" | wc -l`

Expected: Should show ~15 files

**Step 4: Add .gitattributes for DICOM files**

Create `.gitattributes`:
```
*.dcm binary
```

**Step 5: Commit**

```bash
git add tests/fixtures/sample_data.py tests/fixtures/dicom/ .gitattributes
git commit -m "test: add DICOM fixture files for testing

- Add 7 valid DICOM files (CT, MRI, US, XA, multiframe)
- Add 4 edge case files (empty names, special chars, transfer syntaxes)
- Add 3 invalid files (missing required tags)
- Add sample_data.py script to regenerate fixtures

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 7: Update Shared Test Fixtures in conftest.py

**Files:**
- Modify: `tests/conftest.py`

**Step 1: Enhance conftest.py with new fixtures**

Add to the existing `tests/conftest.py`:

```python
"""Test fixtures for Azure DICOM Service Emulator."""

import pytest
from contextlib import asynccontextmanager
from pathlib import Path
from fastapi.testclient import TestClient
from fastapi import FastAPI
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker

from app.database import Base, get_db
from app.routers import dicomweb, changefeed, extended_query_tags, operations, debug, ups
from tests.fixtures.factories import DicomFactory


@pytest.fixture
def client(tmp_path):
    """Create a TestClient with in-memory test database."""

    # Create test database engine
    db_path = tmp_path / "test.db"
    test_engine = create_async_engine(
        f"sqlite+aiosqlite:///{db_path}",
        connect_args={"check_same_thread": False}
    )
    TestSessionLocal = async_sessionmaker(
        test_engine,
        class_=AsyncSession,
        expire_on_commit=False
    )

    # Override get_db dependency
    async def override_get_db():
        async with TestSessionLocal() as session:
            yield session

    # Create a lifespan context for the test app
    @asynccontextmanager
    async def test_lifespan(app: FastAPI):
        # Create tables
        async with test_engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
        yield
        # Cleanup
        await test_engine.dispose()

    # Create test app
    test_app = FastAPI(lifespan=test_lifespan)

    # Register routers
    test_app.include_router(dicomweb.router, prefix="/v2", tags=["DICOMweb"])
    test_app.include_router(changefeed.router, prefix="/v2", tags=["Change Feed"])
    test_app.include_router(extended_query_tags.router, prefix="/v2", tags=["Extended Query Tags"])
    test_app.include_router(operations.router, prefix="/v2", tags=["Operations"])
    test_app.include_router(ups.router, prefix="/v2", tags=["UPS-RS"])
    test_app.include_router(debug.router, tags=["Debug"])

    # Override database dependency
    test_app.dependency_overrides[get_db] = override_get_db

    # Create test client
    with TestClient(test_app) as test_client:
        yield test_client


# ‚îÄ‚îÄ DICOM Fixture Helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


@pytest.fixture
def sample_ct_dicom():
    """Returns CT DICOM bytes (minimal, no pixels)."""
    return DicomFactory.create_ct_image(
        patient_id="FIXTURE-CT-001",
        patient_name="Fixture^CT",
        with_pixel_data=False,
    )


@pytest.fixture
def sample_ct_with_pixels():
    """Returns CT DICOM bytes with pixel data."""
    return DicomFactory.create_ct_image(
        patient_id="FIXTURE-CT-002",
        patient_name="Fixture^CTPixels",
        with_pixel_data=True,
    )


@pytest.fixture
def sample_mri_dicom():
    """Returns MRI DICOM bytes."""
    return DicomFactory.create_mri_image(
        patient_id="FIXTURE-MRI-001",
        patient_name="Fixture^MRI",
        with_pixel_data=True,
    )


@pytest.fixture
def sample_multiframe_dicom():
    """Returns multiframe CT DICOM bytes."""
    return DicomFactory.create_multiframe_ct(
        patient_id="FIXTURE-MULTI-001",
        num_frames=10,
        with_pixel_data=True,
    )


@pytest.fixture
def invalid_dicom_missing_sop():
    """Returns invalid DICOM missing SOPInstanceUID."""
    return DicomFactory.create_invalid_dicom(
        missing_tags=["SOPInstanceUID"]
    )


@pytest.fixture
def invalid_dicom_missing_study():
    """Returns invalid DICOM missing StudyInstanceUID."""
    return DicomFactory.create_invalid_dicom(
        missing_tags=["StudyInstanceUID"]
    )


@pytest.fixture
def fixtures_dir():
    """Returns path to fixtures directory."""
    return Path(__file__).parent / "fixtures" / "dicom"


@pytest.fixture
def valid_dicom_files(fixtures_dir):
    """Returns list of paths to valid DICOM files."""
    return list((fixtures_dir / "valid").glob("*.dcm"))


@pytest.fixture
def edge_case_dicom_files(fixtures_dir):
    """Returns list of paths to edge case DICOM files."""
    return list((fixtures_dir / "edge_cases").glob("*.dcm"))


@pytest.fixture
def invalid_dicom_files(fixtures_dir):
    """Returns list of paths to invalid DICOM files."""
    return list((fixtures_dir / "invalid").glob("*.dcm"))
```

**Step 2: Verify fixtures work**

Create a simple test file `tests/test_fixtures_work.py`:

```python
"""Verify test fixtures are working."""

import pytest


def test_sample_ct_dicom_fixture(sample_ct_dicom):
    """Sample CT fixture should return bytes."""
    assert isinstance(sample_ct_dicom, bytes)
    assert len(sample_ct_dicom) > 0


def test_valid_dicom_files_fixture(valid_dicom_files):
    """Valid DICOM files fixture should return list of files."""
    assert len(valid_dicom_files) >= 7
    assert all(f.suffix == ".dcm" for f in valid_dicom_files)


@pytest.mark.asyncio
async def test_client_fixture(client):
    """Client fixture should provide working test client."""
    response = client.get("/health")
    assert response.status_code == 200
```

**Step 3: Run tests to verify fixtures**

Run: `pytest tests/test_fixtures_work.py -v`

Expected: All 3 tests should pass

**Step 4: Commit**

```bash
git add tests/conftest.py tests/test_fixtures_work.py
git commit -m "test: enhance conftest with DICOM fixtures

- Add sample_ct_dicom, sample_mri_dicom fixtures
- Add invalid_dicom_* fixtures for error testing
- Add fixtures_dir and file list fixtures
- Add test to verify fixtures work correctly

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 8: Audit Existing Tests

**Files:**
- Create: `docs/test-audit.md`

**Step 1: Run existing tests to see current state**

Run: `pytest tests/ -v --tb=short 2>&1 | tee test-audit-output.txt`

Expected: Some tests may fail due to new structure, that's OK

**Step 2: Analyze test results and categorize**

Create `docs/test-audit.md`:

```markdown
# Test Audit Results

**Date:** 2026-02-15
**Total Tests Found:** [COUNT]
**Passing:** [COUNT]
**Failing:** [COUNT]

## Test Categorization

### ‚úÖ Keep As-Is (Passing, Good Quality)

**Unit Tests:**
- `tests/services/test_event_providers.py` - Event provider tests
- `tests/models/test_events.py` - Event model tests
- [Add more after running audit]

**Integration Tests:**
- [Add after audit]

### üîß Needs Refactoring

**Tests to Enhance:**
- [List tests that need improvement]

**Reason:**
- Missing edge cases
- Poor test names
- No docstrings
- Coupling issues

### üóëÔ∏è Delete (Redundant/Obsolete)

- [List tests to delete after audit]

## Migration Plan

1. Move passing unit tests ‚Üí `tests/unit/`
2. Move passing integration tests ‚Üí `tests/integration/`
3. Refactor identified tests
4. Delete redundant tests
5. Update imports

## Test Coverage Baseline

Current coverage: [Run pytest --cov to get baseline]
Target coverage: 90%+
Gap: [Calculate gap]
```

**Step 3: Run actual audit**

Run:
```bash
pytest tests/ -v --co -q | wc -l  # Count total tests
pytest tests/ --cov=app --cov-report=term-missing  # Get baseline coverage
```

**Step 4: Fill in audit document**

Manually review each test file and categorize in `docs/test-audit.md`

**Step 5: Commit audit**

```bash
git add docs/test-audit.md test-audit-output.txt
git commit -m "test: audit existing test suite

- Document current test count and pass rate
- Categorize tests as keep/refactor/delete
- Establish baseline coverage metrics
- Create migration plan for reorganization

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 9: Migrate Passing Tests to New Structure

**Files:**
- Move: Various test files from `tests/` to `tests/unit/` or `tests/integration/`

**Step 1: Identify unit tests to migrate**

Based on audit, tests that test individual functions/classes without API calls:
- `tests/models/test_events.py` ‚Üí `tests/unit/models/test_events.py`
- `tests/services/test_event_providers.py` ‚Üí `tests/unit/services/test_event_providers.py`
- `tests/services/test_event_manager.py` ‚Üí `tests/unit/services/test_event_manager.py`
- `tests/services/test_event_config.py` ‚Üí `tests/unit/services/test_event_config.py`
- `tests/test_frame_extraction.py` ‚Üí `tests/unit/services/test_frame_extraction.py`
- `tests/test_frame_cache.py` ‚Üí `tests/unit/services/test_frame_cache.py`
- `tests/test_image_rendering.py` ‚Üí `tests/unit/services/test_image_rendering.py`
- `tests/test_search_utils.py` ‚Üí `tests/unit/services/test_search_utils.py`
- `tests/test_ups_state_machine.py` ‚Üí `tests/unit/services/test_ups_state_machine.py`
- `tests/test_expiry.py` ‚Üí `tests/unit/services/test_expiry.py`
- `tests/test_upsert.py` ‚Üí `tests/unit/services/test_upsert.py`
- `tests/test_workitem_model.py` ‚Üí `tests/unit/models/test_workitem_model.py`

**Step 2: Move unit tests**

Run:
```bash
# Move model tests
mv tests/models/test_events.py tests/unit/models/
mv tests/test_workitem_model.py tests/unit/models/

# Move service tests
mv tests/services/test_event_providers.py tests/unit/services/
mv tests/services/test_in_memory_provider.py tests/unit/services/
mv tests/services/test_file_provider.py tests/unit/services/
mv tests/services/test_webhook_provider.py tests/unit/services/
mv tests/services/test_azure_queue_provider.py tests/unit/services/
mv tests/services/test_event_manager.py tests/unit/services/
mv tests/services/test_event_config.py tests/unit/services/

# Move other service tests
mv tests/test_frame_extraction.py tests/unit/services/
mv tests/test_frame_cache.py tests/unit/services/
mv tests/test_image_rendering.py tests/unit/services/
mv tests/test_search_utils.py tests/unit/services/
mv tests/test_ups_state_machine.py tests/unit/services/
mv tests/test_expiry.py tests/unit/services/
mv tests/test_upsert.py tests/unit/services/
```

**Step 3: Identify integration tests to migrate**

Tests that use the test client and test API endpoints:
- `tests/test_put_stow.py` ‚Üí `tests/integration/test_stow_rs.py`
- `tests/test_wado_rs_frames.py` ‚Üí `tests/integration/test_wado_rs_frames.py`
- `tests/test_wado_rs_rendered.py` ‚Üí `tests/integration/test_wado_rs_rendered.py`
- `tests/test_qido_fuzzy.py` ‚Üí `tests/integration/test_qido_fuzzy.py`
- `tests/test_qido_wildcard.py` ‚Üí `tests/integration/test_qido_wildcard.py`
- `tests/test_qido_uid_list.py` ‚Üí `tests/integration/test_qido_uid_list.py`
- `tests/test_expiry_integration.py` ‚Üí `tests/integration/test_expiry.py`
- `tests/test_qido_fuzzy_smoke.py` ‚Üí `tests/integration/test_qido_fuzzy_smoke.py`
- `tests/test_qido_wildcard_integration.py` ‚Üí `tests/integration/test_qido_wildcard.py` (merge)
- `tests/test_qido_uid_list_integration.py` ‚Üí `tests/integration/test_qido_uid_list.py` (merge)
- `tests/test_ups_*.py` ‚Üí `tests/integration/test_ups_*.py`

**Step 4: Move integration tests**

Run:
```bash
# Move STOW/WADO/QIDO tests
mv tests/test_put_stow.py tests/integration/test_stow_rs.py
mv tests/test_wado_rs_frames.py tests/integration/
mv tests/test_wado_rs_rendered.py tests/integration/
mv tests/test_qido_fuzzy.py tests/integration/
mv tests/test_qido_wildcard.py tests/integration/
mv tests/test_qido_uid_list.py tests/integration/
mv tests/test_qido_fuzzy_smoke.py tests/integration/
mv tests/test_expiry_integration.py tests/integration/test_expiry.py

# Move UPS tests
mv tests/test_ups_create.py tests/integration/
mv tests/test_ups_retrieve.py tests/integration/
mv tests/test_ups_update.py tests/integration/
mv tests/test_ups_state.py tests/integration/
mv tests/test_ups_cancel.py tests/integration/
mv tests/test_ups_search.py tests/integration/
mv tests/test_ups_subscriptions.py tests/integration/
```

**Step 5: Add pytest markers to migrated tests**

Add `@pytest.mark.unit` or `@pytest.mark.integration` to each test class/function

Example for unit tests:
```python
import pytest

@pytest.mark.unit
class TestDicomEngine:
    def test_something(self):
        ...
```

Example for integration tests:
```python
import pytest

@pytest.mark.integration
class TestStowRS:
    def test_store_instance(self, client):
        ...
```

**Step 6: Run migrated tests**

Run:
```bash
pytest tests/unit/ -v -m unit
pytest tests/integration/ -v -m integration
```

Expected: Tests should pass in new locations

**Step 7: Clean up old directories**

Run:
```bash
# Remove old empty directories
rmdir tests/models tests/services 2>/dev/null || true
```

**Step 8: Commit migration**

```bash
git add tests/
git commit -m "test: migrate existing tests to layered structure

- Move unit tests to tests/unit/ directory
- Move integration tests to tests/integration/ directory
- Add pytest markers (@pytest.mark.unit, @pytest.mark.integration)
- Clean up old directory structure

Migrated:
- 12 unit test files (models, services)
- 17 integration test files (STOW, WADO, QIDO, UPS)

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 10: Configure Security Scanning

**Files:**
- Create: `bandit.yaml`
- Create: `.github/workflows/security.yml`

**Step 1: Create Bandit configuration**

Create `bandit.yaml`:

```yaml
# Bandit security scanner configuration
exclude_dirs:
  - /tests/
  - /venv/
  - /.venv/
  - /build/
  - /dist/

tests:
  - B201  # flask_debug_true
  - B301  # pickle
  - B302  # marshal
  - B303  # md5
  - B304  # insecure_ciphers
  - B305  # insecure_cipher_mode
  - B306  # mktemp_q
  - B307  # eval
  - B308  # mark_safe
  - B309  # httpsconnection
  - B310  # urllib_urlopen
  - B311  # random
  - B312  # telnetlib
  - B313  # xml_bad_cElementTree
  - B314  # xml_bad_ElementTree
  - B315  # xml_bad_expatreader
  - B316  # xml_bad_expatbuilder
  - B317  # xml_bad_sax
  - B318  # xml_bad_minidom
  - B319  # xml_bad_pulldom
  - B320  # xml_bad_etree
  - B321  # ftplib
  - B323  # unverified_context
  - B324  # hashlib_insecure_functions
  - B401  # import_telnetlib
  - B402  # import_ftplib
  - B403  # import_pickle
  - B404  # import_subprocess
  - B405  # import_xml_etree
  - B406  # import_xml_sax
  - B407  # import_xml_expat
  - B408  # import_xml_minidom
  - B409  # import_xml_pulldom
  - B410  # import_lxml
  - B411  # import_xmlrpclib
  - B412  # import_httpoxy
  - B413  # import_pycrypto
  - B501  # request_with_no_cert_validation
  - B502  # ssl_with_bad_version
  - B503  # ssl_with_bad_defaults
  - B504  # ssl_with_no_version
  - B505  # weak_cryptographic_key
  - B506  # yaml_load
  - B507  # ssh_no_host_key_verification
  - B601  # paramiko_calls
  - B602  # subprocess_popen_with_shell_equals_true
  - B603  # subprocess_without_shell_equals_true
  - B604  # any_other_function_with_shell_equals_true
  - B605  # start_process_with_a_shell
  - B606  # start_process_with_no_shell
  - B607  # start_process_with_partial_path
  - B608  # hardcoded_sql_expressions
  - B609  # linux_commands_wildcard_injection
  - B610  # django_extra_used
  - B611  # django_rawsql_used
  - B701  # jinja2_autoescape_false
  - B702  # use_of_mako_templates
  - B703  # django_mark_safe

skips:
  - B101  # assert_used (we use asserts in tests)
```

**Step 2: Run initial security scan**

Run: `bandit -r app/ -c bandit.yaml -ll`

Expected: Should show any medium/high security issues (target: zero)

**Step 3: Create GitHub Actions security workflow**

Create `.github/workflows/security.yml`:

```yaml
name: Security Scan

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    # Run nightly at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  bandit:
    name: Bandit Security Scan
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Bandit
        run: pip install bandit[toml]

      - name: Run Bandit
        run: |
          bandit -r app/ -c bandit.yaml -ll -f json -o bandit-report.json
          bandit -r app/ -c bandit.yaml -ll

      - name: Upload Bandit report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: bandit-security-report
          path: bandit-report.json

  safety:
    name: Safety Dependency Check
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install safety
          pip install -e ".[dev]"

      - name: Run Safety check
        run: safety check --json --output safety-report.json || true

      - name: Upload Safety report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: safety-dependency-report
          path: safety-report.json
```

**Step 4: Commit security configuration**

```bash
git add bandit.yaml .github/workflows/security.yml
git commit -m "ci: add security scanning with Bandit and Safety

- Configure Bandit for Python security scanning
- Add GitHub Actions workflow for security scans
- Run nightly security checks
- Upload security reports as artifacts

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 11: Configure Pre-commit Hooks

**Files:**
- Create: `.pre-commit-config.yaml`

**Step 1: Create pre-commit configuration**

Create `.pre-commit-config.yaml`:

```yaml
# Pre-commit hooks for code quality
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.8.0
    hooks:
      # Run linter
      - id: ruff
        args: [--fix]
      # Run formatter
      - id: ruff-format

  - repo: https://github.com/PyCQA/bandit
    rev: '1.7.6'
    hooks:
      - id: bandit
        args: [-ll, -c, bandit.yaml, -r, app/]
        pass_filenames: false

  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
        args: ['--maxkb=1000']
      - id: check-merge-conflict
      - id: check-toml
      - id: detect-private-key
```

**Step 2: Install pre-commit**

Run:
```bash
pip install pre-commit
pre-commit install
```

Expected: "pre-commit installed at .git/hooks/pre-commit"

**Step 3: Run pre-commit on all files**

Run: `pre-commit run --all-files`

Expected: All hooks should pass (may auto-fix some files)

**Step 4: Commit pre-commit configuration**

```bash
git add .pre-commit-config.yaml
git commit -m "ci: add pre-commit hooks for code quality

- Add ruff linter and formatter hooks
- Add bandit security scanning hook
- Add trailing whitespace, YAML, TOML checks
- Add large file and private key detection

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 12: Create GitHub Actions Test Workflow

**Files:**
- Create: `.github/workflows/tests.yml`

**Step 1: Create comprehensive test workflow**

Create `.github/workflows/tests.yml`:

```yaml
name: Tests

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    name: Test Suite
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.12', '3.13']

    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_dicom
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -e ".[dev]"

      - name: Run linting
        run: ruff check app/ tests/

      - name: Run type checking
        run: mypy app/

      - name: Run unit tests
        run: |
          pytest tests/unit/ -v -m unit \
            --cov=app \
            --cov-report=xml \
            --cov-report=term-missing \
            --junitxml=junit-unit.xml

      - name: Run integration tests
        env:
          DATABASE_URL: postgresql+asyncpg://test:test@localhost:5432/test_dicom
        run: |
          pytest tests/integration/ -v -m integration \
            --cov=app --cov-append \
            --cov-report=xml \
            --cov-report=term-missing \
            --junitxml=junit-integration.xml

      - name: Run E2E tests
        env:
          DATABASE_URL: postgresql+asyncpg://test:test@localhost:5432/test_dicom
        run: |
          pytest tests/e2e/ -v -m e2e \
            --junitxml=junit-e2e.xml

      - name: Check coverage threshold
        run: |
          coverage report --fail-under=90

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage.xml
          fail_ci_if_error: true
          token: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.python-version }}
          path: junit-*.xml

  performance:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    needs: test

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install -e ".[dev]"

      - name: Run benchmarks
        run: |
          pytest tests/performance/ --benchmark-only \
            --benchmark-json=benchmark-results.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark-results.json
```

**Step 2: Commit test workflow**

```bash
git add .github/workflows/tests.yml
git commit -m "ci: add comprehensive GitHub Actions test workflow

- Run tests on Python 3.12 and 3.13
- Set up PostgreSQL service for integration tests
- Run unit, integration, and E2E tests separately
- Check 90% coverage threshold
- Upload coverage to Codecov
- Run performance benchmarks
- Upload test results and benchmark artifacts

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 13: Create Test Documentation

**Files:**
- Create: `tests/README.md`

**Step 1: Write comprehensive test documentation**

Create `tests/README.md`:

```markdown
# Test Suite Documentation

## Overview

Comprehensive test suite for Azure DICOM Service Emulator with 90%+ code coverage target.

## Test Organization

```
tests/
‚îú‚îÄ‚îÄ unit/           # Unit tests (isolated, no DB/API)
‚îú‚îÄ‚îÄ integration/    # API integration tests
‚îú‚îÄ‚îÄ e2e/            # End-to-end workflow tests
‚îú‚îÄ‚îÄ performance/    # Benchmarks and load tests
‚îú‚îÄ‚îÄ security/       # Security scans
‚îú‚îÄ‚îÄ fixtures/       # Test data and DICOM files
‚îî‚îÄ‚îÄ conftest.py     # Shared fixtures
```

## Running Tests

### All Tests
```bash
pytest
```

### By Layer
```bash
pytest tests/unit/ -m unit
pytest tests/integration/ -m integration
pytest tests/e2e/ -m e2e
```

### With Coverage
```bash
pytest --cov=app --cov-report=html
open htmlcov/index.html
```

### Parallel Execution
```bash
pytest -n auto  # Uses all CPU cores
```

### Specific Test
```bash
pytest tests/unit/services/test_dicom_engine.py::TestDicomEngine::test_parse_valid_dicom -v
```

## Test Markers

- `@pytest.mark.unit` - Unit tests
- `@pytest.mark.integration` - Integration tests
- `@pytest.mark.e2e` - End-to-end tests
- `@pytest.mark.slow` - Tests >1 second
- `@pytest.mark.security` - Security tests

Filter by marker:
```bash
pytest -m "unit and not slow"
pytest -m integration
```

## Test Fixtures

### DICOM Fixtures
- `sample_ct_dicom` - CT image bytes
- `sample_mri_dicom` - MRI image bytes
- `sample_multiframe_dicom` - Multiframe CT
- `invalid_dicom_missing_sop` - Invalid DICOM (missing SOP UID)
- `valid_dicom_files` - List of valid DICOM file paths
- `edge_case_dicom_files` - Edge case DICOM files

### Database Fixtures
- `client` - FastAPI TestClient with test database
- `db` - Async database session

### Example Usage
```python
def test_store_ct_image(client, sample_ct_dicom):
    response = client.post("/v2/studies", files={"file": sample_ct_dicom})
    assert response.status_code == 200
```

## Writing Tests

### Unit Test Example
```python
import pytest
from app.services.dicom_engine import DicomEngine

@pytest.mark.unit
class TestDicomEngine:
    def test_extract_metadata(self, sample_ct_dicom):
        """Should extract metadata from valid DICOM."""
        metadata = DicomEngine.extract_metadata(sample_ct_dicom)
        assert metadata["StudyInstanceUID"]
        assert metadata["PatientID"] == "FIXTURE-CT-001"
```

### Integration Test Example
```python
import pytest

@pytest.mark.integration
class TestStowRS:
    def test_store_instance(self, client, sample_ct_dicom):
        """Should store DICOM instance successfully."""
        response = client.post(
            "/v2/studies",
            files={"file": ("test.dcm", sample_ct_dicom, "application/dicom")}
        )
        assert response.status_code == 200
        data = response.json()
        assert data["ReferencedSOPSequence"]
```

## Coverage Goals

| Component | Target Coverage |
|-----------|----------------|
| Services  | 90%+ |
| Models    | 90%+ |
| Routers   | 98%+ (critical paths) |
| Overall   | 90%+ |

## Performance Benchmarks

Run performance tests:
```bash
pytest tests/performance/ --benchmark-only
```

View benchmark comparison:
```bash
pytest tests/performance/ --benchmark-compare
```

## Security Testing

Run security scans:
```bash
bandit -r app/ -c bandit.yaml -ll
safety check
```

## CI/CD Integration

Tests run automatically on:
- Every push to main
- Every pull request
- Nightly (full suite + security scans)

Quality gates:
- ‚úÖ All tests pass
- ‚úÖ Coverage ‚â•90%
- ‚úÖ No linting errors
- ‚úÖ No security issues (medium+)
- ‚úÖ Performance benchmarks pass

## Troubleshooting

### Tests failing locally but passing in CI
- Check Python version (tests run on 3.12, 3.13)
- Check database state (use fresh test DB)
- Run with `-v` for verbose output

### Coverage not increasing
- Check if new code is in `app/` directory
- Check if tests are actually executing (`pytest --collect-only`)
- Look for excluded patterns in `.coveragerc`

### Slow test suite
- Use `pytest -n auto` for parallel execution
- Mark slow tests with `@pytest.mark.slow`
- Run fast tests first: `pytest -m "not slow"`
```

**Step 2: Commit test documentation**

```bash
git add tests/README.md
git commit -m "docs: add comprehensive test suite documentation

- Document test organization and structure
- Add examples for running tests by layer
- Document test fixtures and markers
- Provide unit and integration test examples
- Document coverage goals and CI/CD integration
- Add troubleshooting guide

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 14: Verify Complete Phase 1 Setup

**Files:**
- None (verification only)

**Step 1: Run complete test suite**

Run:
```bash
pytest tests/ -v --cov=app --cov-report=term-missing
```

Expected: Tests run successfully (may have low coverage at this phase)

**Step 2: Verify directory structure**

Run: `tree tests -L 2 -d`

Expected output:
```
tests
‚îú‚îÄ‚îÄ e2e
‚îú‚îÄ‚îÄ fixtures
‚îÇ   ‚îî‚îÄ‚îÄ dicom
‚îú‚îÄ‚îÄ integration
‚îú‚îÄ‚îÄ performance
‚îÇ   ‚îî‚îÄ‚îÄ load_tests
‚îú‚îÄ‚îÄ security
‚îî‚îÄ‚îÄ unit
    ‚îú‚îÄ‚îÄ models
    ‚îú‚îÄ‚îÄ services
    ‚îî‚îÄ‚îÄ utils
```

**Step 3: Verify CI/CD workflows**

Run:
```bash
ls -la .github/workflows/
```

Expected: `tests.yml` and `security.yml` present

**Step 4: Verify pre-commit hooks**

Run: `pre-commit run --all-files`

Expected: All hooks pass

**Step 5: Generate final coverage report**

Run:
```bash
pytest --cov=app --cov-report=html
open htmlcov/index.html
```

Review coverage report and identify gaps for Phase 2

**Step 6: Create Phase 1 completion summary**

Create `docs/phase1-completion.md`:

```markdown
# Phase 1 Completion Summary

**Date:** [TODAY]
**Status:** ‚úÖ COMPLETE

## Deliverables

### ‚úÖ Testing Tools Installed
- pytest, pytest-cov, pytest-asyncio
- pytest-xdist, pytest-html, pytest-benchmark
- bandit, safety, locust
- faker, factory-boy

### ‚úÖ Directory Structure
- Layered organization (unit/integration/e2e/performance/security)
- Fixture library with 15+ DICOM samples
- Test factories for data generation

### ‚úÖ Test Infrastructure
- Shared fixtures in conftest.py
- Pytest markers configured
- Coverage configuration (.coveragerc)
- Pre-commit hooks (.pre-commit-config.yaml)

### ‚úÖ CI/CD Integration
- GitHub Actions test workflow
- GitHub Actions security workflow
- Codecov integration ready
- Nightly security scans

### ‚úÖ Documentation
- tests/README.md with comprehensive guide
- Test audit completed
- Migration plan executed

### ‚úÖ Test Migration
- 12 unit tests migrated
- 17 integration tests migrated
- All tests passing in new structure

## Metrics

| Metric | Value |
|--------|-------|
| Total tests | [COUNT] |
| Unit tests | [COUNT] |
| Integration tests | [COUNT] |
| Current coverage | [%]% |
| Target coverage | 90% |
| Gap | [%]% |

## Next Steps (Phase 2)

1. Write unit tests for all services
2. Achieve 90%+ coverage on app/services/
3. Achieve 90%+ coverage on app/models/
4. Target: 200-300 unit tests total

## Issues/Blockers

[List any issues encountered or blockers for Phase 2]
```

**Step 7: Final commit**

```bash
git add docs/phase1-completion.md
git commit -m "docs: Phase 1 (Foundation) completion summary

Phase 1 deliverables completed:
- ‚úÖ Testing tools installed and configured
- ‚úÖ Layered test directory structure
- ‚úÖ DICOM fixture library (15+ samples)
- ‚úÖ Test factories and shared fixtures
- ‚úÖ Existing tests audited and migrated
- ‚úÖ CI/CD workflows (tests + security)
- ‚úÖ Pre-commit hooks configured
- ‚úÖ Comprehensive test documentation

Current baseline coverage: [%]%
Target for Phase 2: 90%+ on services/models

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Phase 1 Completion Checklist

- [ ] Task 1: Testing dependencies installed
- [ ] Task 2: Pytest markers configured
- [ ] Task 3: Coverage configuration created
- [ ] Task 4: Layered directory structure created
- [ ] Task 5: DICOM factory created
- [ ] Task 6: 15+ DICOM fixture files generated
- [ ] Task 7: Shared fixtures added to conftest.py
- [ ] Task 8: Existing tests audited
- [ ] Task 9: Tests migrated to new structure
- [ ] Task 10: Security scanning configured
- [ ] Task 11: Pre-commit hooks configured
- [ ] Task 12: GitHub Actions test workflow created
- [ ] Task 13: Test documentation written
- [ ] Task 14: Phase 1 verification complete

## Success Criteria

‚úÖ All testing tools installed
‚úÖ Layered test structure in place
‚úÖ DICOM fixture library with 15+ samples
‚úÖ Test factories working
‚úÖ Existing tests migrated and passing
‚úÖ CI/CD workflows configured
‚úÖ Pre-commit hooks working
‚úÖ Documentation complete

**Phase 1 Duration:** 1-2 weeks
**Next Phase:** Phase 2 - Unit Tests (Week 3-4)
